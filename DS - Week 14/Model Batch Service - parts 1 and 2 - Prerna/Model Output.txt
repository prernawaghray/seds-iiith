pwaghray@pwaghray-ltm2 Model_Batch_Service % docker run batch_service python3 inference.py
Linux-5.10.124-linuxkit-x86_64-with-glibc2.35
Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:35:26) [GCC 10.4.0]
NumPy 1.22.4
SciPy 1.9.1
Shape of the test data
(1300, 160)
(1300,)
lda.joblib
LDA score and classification:
0.6915384615384615
LDA Prediction: [ 0  0  0 ... 25 25 25]
LDA Classification Report:               precision    recall  f1-score   support

           0       0.57      0.90      0.70        50
           1       1.00      0.32      0.48        50
           2       1.00      0.88      0.94        50
           3       0.22      0.32      0.26        50
           4       0.00      0.00      0.00        50
           5       0.59      0.68      0.63        50
           6       0.89      0.80      0.84        50
           7       0.14      0.10      0.12        50
           8       0.42      0.88      0.57        50
           9       0.92      0.44      0.59        50
          10       0.61      0.80      0.69        50
          11       0.75      0.80      0.78        50
          12       1.00      1.00      1.00        50
          13       1.00      0.92      0.96        50
          14       1.00      0.04      0.08        50
          15       0.00      0.00      0.00        50
          16       0.10      0.22      0.14        50
          17       1.00      1.00      1.00        50
          18       1.00      1.00      1.00        50
          19       1.00      1.00      1.00        50
          20       1.00      1.00      1.00        50
          21       1.00      1.00      1.00        50
          22       1.00      1.00      1.00        50
          23       1.00      1.00      1.00        50
          24       0.89      1.00      0.94        50
          25       0.90      0.88      0.89        50

    accuracy                           0.69      1300
   macro avg       0.73      0.69      0.68      1300
weighted avg       0.73      0.69      0.68      1300

NN score and classification:
0.6615384615384615
NN Prediction: [ 0  0  0 ... 25 25 24]
NN Classification Report:               precision    recall  f1-score   support

           0       0.75      1.00      0.85        50
           1       1.00      0.64      0.78        50
           2       0.96      0.90      0.93        50
           3       0.06      0.06      0.06        50
           4       0.40      0.16      0.23        50
           5       0.41      0.42      0.42        50
           6       0.85      0.90      0.87        50
           7       0.15      0.20      0.17        50
           8       0.40      0.52      0.45        50
           9       0.58      0.72      0.64        50
          10       0.62      0.32      0.42        50
          11       0.62      0.74      0.67        50
          12       0.86      0.86      0.86        50
          13       0.82      0.80      0.81        50
          14       0.38      0.20      0.26        50
          15       0.04      0.04      0.04        50
          16       0.00      0.00      0.00        50
          17       0.96      1.00      0.98        50
          18       1.00      1.00      1.00        50
          19       1.00      1.00      1.00        50
          20       0.98      1.00      0.99        50
          21       1.00      1.00      1.00        50
          22       0.93      0.84      0.88        50
          23       0.93      1.00      0.96        50
          24       0.89      1.00      0.94        50
          25       1.00      0.88      0.94        50

    accuracy                           0.66      1300
   macro avg       0.68      0.66      0.66      1300
weighted avg       0.68      0.66      0.66      1300

RF score and classification:
0.6323076923076923
RF Prediction: [ 0  0  0 ... 25 25 25]
RF Classification Report:               precision    recall  f1-score   support

           0       0.74      0.86      0.80        50
           1       1.00      0.56      0.72        50
           2       0.98      1.00      0.99        50
           3       0.11      0.12      0.12        50
           4       0.28      0.18      0.22        50
           5       0.42      0.16      0.23        50
           6       0.75      0.78      0.76        50
           7       0.04      0.04      0.04        50
           8       0.23      0.44      0.30        50
           9       0.73      0.74      0.73        50
          10       0.64      0.56      0.60        50
          11       0.71      0.74      0.73        50
          12       0.76      0.50      0.60        50
          13       0.60      0.84      0.70        50
          14       0.60      0.42      0.49        50
          15       0.00      0.00      0.00        50
          16       0.00      0.00      0.00        50
          17       0.74      0.84      0.79        50
          18       1.00      1.00      1.00        50
          19       1.00      1.00      1.00        50
          20       1.00      1.00      1.00        50
          21       1.00      1.00      1.00        50
          22       0.97      0.76      0.85        50
          23       0.94      0.92      0.93        50
          24       0.91      1.00      0.95        50
          25       0.78      0.98      0.87        50

    accuracy                           0.63      1300
   macro avg       0.65      0.63      0.63      1300
weighted avg       0.65      0.63      0.63      1300

pwaghray@pwaghray-ltm2 Model_Batch_Service % 
